---
title: "Project Academic Performance Analysis"
author: "Deni Permana - Diaz Fahreza Akbar"
date: "2024-11-24"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 0. Import Library
Library yang akan digunakan

```{r}
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(rpart)
library(cluster)
library(factoextra)
library(corrplot)
library(ggplot2)
library(reshape2)
library(stats)
library(NbClust)
```

# 1. Import Dataset
Dataset yang akan digunakan

```{r}
# 1. Student Mat
student_mat_data <- read_delim("resources/dataset/student-mat.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)

# 2. Student Por
student_por_data <- read_delim("resources/dataset/student-por.csv", 
    delim = ";", escape_double = FALSE, trim_ws = TRUE)
```

# 2. Exploration Data

```{r}
# 1. Display Data
head(student_mat_data, 5)

head(student_por_data, 5)
```

```{r}
# 2. Display Data Structure
cat("STUDENT MAT DATA\n")
str(student_mat_data)

cat("\nSTUDENT POR DATA\n")
str(student_por_data)
```

```{r}
# 3. Descriptive Stats
cat("STUDENT MAT DATA\n")
summary(student_mat_data)

cat("\nSTUDENT POR DATA\n")
summary(student_por_data)
```

# 3. Cleaning Data

```{r}
# 1. Merge Datasets
student_mat_data$course <- "Math"
student_por_data$course <- "Portuguese"
student_data <- bind_rows(student_mat_data, student_por_data)
```

```{r}
# 2. Select Columns
selected_columns <- c("sex", "age", "address", "studytime", "failures", 
                      "schoolsup", "famsup", "freetime", "goout", "romantic", 
                      "G1", "G2", "G3")
student_data <- student_data[, selected_columns]
```

```{r}
# 3. Pre-Process Categorical Data
student_data <- student_data %>%
  mutate(
    sex = ifelse(sex == "F", 0, 1),
    address = ifelse(address == "U", 0, 1),
    schoolsup = ifelse(schoolsup == "no", 0, 1),
    famsup = ifelse(famsup == "no", 0, 1),
    romantic = ifelse(romantic == "no", 0, 1)
  )
```

```{r}
# 4. Handle Empty Values
student_data <- na.omit(student_data)
```

```{r}
# 6. Display Cleared Data
head(student_data, 5)
```

# 4. Pre-Processing

```{r}
# 1. Functions for data preparation
student_prepare_data <- function(student_data) {
  # Split features for regression and classification
  X <- student_data %>%
    select(G1, G2, studytime, failures, freetime, goout)
  
  # Target for regression
  y_reg <- student_data$G3
  
  # Target for classification with categorization
  y_class <- cut(student_data$G3,
                 breaks = c(0, 10, 15, 20),
                 labels = c('low', 'medium', 'high'))
  
  # Return list with all variables
  list(X = X, y_reg = y_reg, y_class = y_class)
}
```

```{r}
# 2. Analysis execution
student_data_processed <- student_prepare_data(student_data)
```

# 4. Regression

```{r}
# 1. Function for regression modeling
student_perform_regression <- function(X, y_reg) {
  # Split data
  set.seed(42)
  split_index <- createDataPartition(y_reg, p = 0.8, list = FALSE)
  
  X_train <- X[split_index, ]
  X_test <- X[-split_index, ]
  y_train <- y_reg[split_index]
  y_test <- y_reg[-split_index]
  
  # Random Forest Model
  rf_model <- randomForest(
    x = X_train,
    y = y_train,
    ntree = 100,
    random_state = 42
  )
  
  # Predict
  y_pred <- predict(rf_model, X_test)
  
  # Evaluation
  mae <- mean(abs(y_test - y_pred))
  rmse <- sqrt(mean((y_test - y_pred)^2))

  # Fitur importance
  feature_importance <- data.frame(
    Feature = colnames(X),
    Importance = importance(rf_model)
  )

  # Return result
  list(
    model = rf_model,
    predictions = y_pred,
    mae = mae,
    rmse = rmse,
    feature_importance = feature_importance
  )
}
```

```{r}
# 2. Regression
student_regression_results <- student_perform_regression(
  student_data_processed$X,
  student_data_processed$y_reg
)
```

```{r}
# 3. Display results
cat("Regresi - Pentingnya Fitur:")
print(student_regression_results$feature_importance)
```

```{r}
print("Regresi - Metrik:")
print(paste("MAE:", student_regression_results$mae))
print(paste("RMSE:", student_regression_results$rmse))
```

# 5. Classification

```{r}
# 1. Function for classification modeling
student_perform_classification <- function(X, y_class) {
  # Split data
  set.seed(42)
  split_index <- createDataPartition(y_class, p = 0.8, list = FALSE)
  
  X_train <- X[split_index, ]
  X_test <- X[-split_index, ]
  y_train <- y_class[split_index]
  y_test <- y_class[-split_index]
  
  # Handle Missing values
  X_train <- X_train %>%
    mutate(across(everything(), ~replace_na(., mean(., na.rm = TRUE))))
  
  X_test <- X_test %>%
    mutate(across(everything(), ~replace_na(., mean(., na.rm = TRUE))))
  
  # Decision Tree Model
  dt_model <- rpart(
    formula = y_train ~ .,
    data = data.frame(X_train, y_train),
    method = "class"
  )  
  
  # Predict
  y_pred <- predict(dt_model, X_test, type = "class")
  
  # Evaluation
  conf_matrix <- confusionMatrix(y_pred, y_test)
  
  # Return result
  list(
    model = dt_model,
    predictions = y_pred,
    confusion_matrix = conf_matrix
  )
}
```

```{r}
# 2. Classification
student_classification_results <- student_perform_classification(
  student_data_processed$X,
  student_data_processed$y_class
)
```

```{r}
# 3. Display result
print("Klasifikasi - Confusion Matrix:")
print(student_classification_results$confusion_matrix)
```

# 6. Clustering

```{r}
# Function for clustering analysis
student_perform_clustering_analysis <- function(student_data) {
  # Prepare data for clustering
  student_clustering_data <- student_data %>%
    select(studytime, freetime, goout) %>%
    scale()  # Standardize the data
  
  # 1. Elbow Method to determine the optimal number of clusters
  student_elbow_method <- function(student_data) {
    # Calculate total within-cluster sum of squares for various k values
    wss <- sapply(1:10, function(k) {
      kmeans(student_data, centers = k, nstart = 25)$tot.withinss
    })
    
    # Plot the Elbow Method
    student_plt_elbow <- ggplot(data.frame(k = 1:10, wss = wss), 
                                aes(x = k, y = wss)) +
      geom_line() +
      geom_point() +
      labs(title = "Elbow Method for Optimal Clusters",
           x = "Number of Clusters (k)",
           y = "Total Within-Cluster Sum of Squares")
    
    print(student_plt_elbow)
    return(wss)
  }
  
  # Execute Elbow Method
  student_elbow_method(student_clustering_data)
  
  # 2. Perform K-Means clustering
  student_perform_kmeans <- function(student_data, k = 3) {
    set.seed(42)
    # Apply K-Means clustering
    student_km_result <- kmeans(student_data, centers = k, nstart = 25)
    
    # Analyze silhouette
    student_sil <- silhouette(student_km_result$cluster, dist(student_data))
    
    # Plot silhouette
    student_plt_sil <- fviz_silhouette(student_sil) +
      labs(title = "Silhouette Plot")
    print(student_plt_sil)
    
    return(list(
      student_kmeans = student_km_result,
      silhouette = student_sil
    ))
  }
  
  # Run K-Means clustering
  student_km_results <- student_perform_kmeans(student_clustering_data)
  
  # 3. Visualize clustering with PCA
  student_pca_visualization <- function(student_data, clusters) {
    # Perform PCA
    student_pca_result <- prcomp(student_data)
    
    # Extract the first two principal components
    student_pca_data <- as.data.frame(student_pca_result$x[, 1:2])
    student_pca_data$Cluster <- as.factor(clusters)
    
    # Plot PCA
    student_plt_pca <- ggplot(student_pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
      geom_point(alpha = 0.7) +
      labs(title = "Clustering Visualization (PCA)",
           x = "First Principal Component",
           y = "Second Principal Component") +
      theme_minimal()
    
    print(student_plt_pca)
  }
  
  # Perform PCA visualization
  student_pca_visualization(student_clustering_data, student_km_results$student_kmeans$cluster)
  
  # 4. Analyze cluster characteristics
  student_cluster_analysis <- student_data %>%
    mutate(Cluster = student_km_results$student_kmeans$cluster) %>%
    group_by(Cluster) %>%
    summarise(
      mean_studytime = mean(studytime),
      mean_freetime = mean(freetime),
      mean_goout = mean(goout)
    )
  
  print("Cluster Characteristics:")
  print(student_cluster_analysis)
  
  # 5. Visualize correlation matrix
  student_correlation_matrix <- cor(student_data %>% select(studytime, freetime, goout, G1, G2, G3))
  
  corrplot(
    student_correlation_matrix, 
    method = "color", 
    type = "full",
    title = "Correlation Matrix"
  )
  
  # 6. Distribution of performance categories
  y_class <- cut(student_data$G3, 
                 breaks = c(0, 10, 15, 20), 
                 labels = c('low', 'medium', 'high'))
  
  student_plt_dist <- ggplot(data.frame(y_class), aes(x = y_class)) +
    geom_bar(fill = "skyblue") +
    labs(title = "Distribution of Performance Categories",
         x = "Performance Category",
         y = "Number of Students")
  
  print(student_plt_dist)
  
  # Return all results
  return(list(
    student_kmeans_result = student_km_results,
    student_cluster_characteristics = student_cluster_analysis
  ))
}
```

```{r}
# Run clustering analysis
student_clustering_results <- student_perform_clustering_analysis(student_data)
```

